---
layout: post
title: Correlating random numbers
---

Let's assume that we want generate samples from a multivariate normal distribution. 

First we assume we know how to generate samples from a univariate gaussian distribution.

So we have n independent random variables $x_1, x_2,..., x_n$ where $x_i \sim \mathcal{N(0,1)}$

$\langle \vec{x} \rangle =0$ and $\langle \vec{x} \vec{x}^T \rangle = \mathbb{1}$.

and what we aim to find is a linear mapping $M: \vec{x} \mapsto \vec{y}$. 

Where the new variable $y$ has a covariance matrix $C$, where $C=\langle \vec{y}  \vec{y}^T\rangle$ which we can specify as we wish.
 
So we want to find a transformation matrix $M$ where $M \vec{x} = \vec{y}$.

$C = \langle \vec{y}  \vec{y}^T\rangle = \langle M \vec{x}  (M \vec{x})^\intercal\rangle = \langle M \vec{x}   \vec{x}^\intercal M^\intercal \rangle$ .

Now let's remember that the covariance matrix $C$ has to be a symmetric(hermitian) and positive definite matrix. For those kind of matrices we can always decompose it into the product of a lower triangular matrix $L$ and its transpose $L^\intercal$ (https://en.wikipedia.org/wiki/Cholesky_decomposition).

$ C = L \ L^\intercal$

This is called the Cholesky decomposition.





We can easily generate samples from a univariate normal distribution using:

```python
s = "Python syntax highlighting"
print s
```

##