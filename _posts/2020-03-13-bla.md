---
layout: post
title: Correlating random numbers
---

Let's assume that we want generate samples from a multivariate normal distribution. 

First we assume we know how to generate samples from a univariate gaussian distribution.

So we have n independent random variables $x_1, x_2,..., x_n$ where $x_i \sim \mathcal{N(0,1)}$

$\langle \vec{x} \rangle =0$ and $\langle \vec{x} \vec{x}^T \rangle = \mathbb{1}$.

and what we aim to find is a linear mapping $M: \vec{x} \mapsto \vec{y}$. 

Where the new variable $y$ has a covariance matrix $C$, where $C=\langle \vec{y}  \vec{y}^T\rangle$ which we can specify as we wish.
 
So we want to find a transformation matrix $M$ where $M \vec{x} = \vec{y}$.

$C = \langle \vec{y}  \vec{y}^T\rangle = \langle M \vec{x}  (M \vec{x})^\intercal\rangle = \langle M \vec{x}   \vec{x}^\intercal M^\intercal \rangle$ .

Now let's remember that the covariance matrix $C$ has to be a symmetric(hermitian) and positive definite matrix. For those kind of matrices we can always decompose it into the product of a lower triangular matrix $L$ and its transpose $L^\intercal$ (https://en.wikipedia.org/wiki/Cholesky_decomposition).

$ C = L \ L^T$

This is called the Cholesky decomposition.





We can easily generate samples from a univariate normal distribution using:

```python
import numpy as np 
import matplotlib.pyplot as plt

d = 2
n = 100000 

# first we create our samples from the 2 independent normal distributions
x = np.random.normal(loc=0, scale=1, size=d*n).reshape(d, n)

# now we specify our covariance matrix
K_0 = np.array([[2, 1],
                [1, 2]])
# we calculate the Cholesky deomposition - L is the lower diagonal matrix
L = np.linalg.cholesky(K_0) 
y = np.dot(L, x)

# now let's see how the new distribution 
```

##